{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18449c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple PROPN nsubj\n",
      "is AUX aux\n",
      "looking VERB ROOT\n",
      "at ADP prep\n",
      "buying VERB pcomp\n",
      "U.K PROPN dobj\n",
      "startup VERB dep\n",
      "for ADP prep\n",
      "1 NUM compound\n",
      "billion NUM nummod\n",
      "dollars($ PROPN pobj\n",
      ") PUNCT punct\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp('Apple is looking at buying U.K startup for 1 billion dollars($)')\n",
    "\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e628b283",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "During processing, spaCy first tokenizes the text, i.e segment it into words, punctuations and so on. This is done by applying rules specific to each language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d223923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Let's go to N.Y.!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b143c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Let's go to N.Y.!\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29f0a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6142164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53e18ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Let's go to N.Y.!"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64a6b684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let\n",
      "'s\n",
      "go\n",
      "to\n",
      "N.Y.\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "for token in docs:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd7c243",
   "metadata": {},
   "source": [
    "### Part-Of-Speech Tagging and Dependency Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1835b92",
   "metadata": {},
   "source": [
    "**Text** : The original word text.\n",
    "\n",
    "**Lemma** : The base form of the word.\n",
    "\n",
    "**POS** : The simple UPOS part-of-speech tag.\n",
    "\n",
    "**Tag** : The detailed part-of-speech tag.\n",
    "\n",
    "**Dep** : Synthetic dependency, i.e. the relation between tokens.\n",
    "\n",
    "**Shape** : The word shape - capitalization, punctuation, digits.\n",
    "\n",
    "**is alpha** : is the toekn an alpha characters?\n",
    "\n",
    "**is stop** : is the token part of a stop list, i.e. the most common words of the language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "543e4794",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14ba263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e92f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Apple is looking at buying U.K. startup for $a billion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca41c958",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c474f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from beautifultable import BeautifulTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1abe57ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = BeautifulTable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd304b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "table.columns.header = ['text','POS','TAG','Dep','Shape','is_alpha','is_stop']\n",
    "for token in doc:\n",
    "    table.rows.append([token.text, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ac0d4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-----+----------+-------+----------+---------+\n",
      "|  text   |  POS  | TAG |   Dep    | Shape | is_alpha | is_stop |\n",
      "+---------+-------+-----+----------+-------+----------+---------+\n",
      "|  Apple  | PROPN | NNP |  nsubj   | Xxxxx |    1     |    0    |\n",
      "+---------+-------+-----+----------+-------+----------+---------+\n",
      "|   is    |  AUX  | VBZ |   aux    |  xx   |    1     |    1    |\n",
      "+---------+-------+-----+----------+-------+----------+---------+\n",
      "| looking | VERB  | VBG |   ROOT   | xxxx  |    1     |    0    |\n",
      "+---------+-------+-----+----------+-------+----------+---------+\n",
      "|   at    |  ADP  | IN  |   prep   |  xx   |    1     |    1    |\n",
      "+---------+-------+-----+----------+-------+----------+---------+\n",
      "| buying  | VERB  | VBG |  pcomp   | xxxx  |    1     |    0    |\n",
      "+---------+-------+-----+----------+-------+----------+---------+\n",
      "|  U.K.   | PROPN | NNP |   dobj   | X.X.  |    0     |    0    |\n",
      "+---------+-------+-----+----------+-------+----------+---------+\n",
      "| startup | VERB  | VB  |   dep    | xxxx  |    1     |    0    |\n",
      "+---------+-------+-----+----------+-------+----------+---------+\n",
      "|   for   |  ADP  | IN  |   prep   |  xxx  |    1     |    1    |\n",
      "+---------+-------+-----+----------+-------+----------+---------+\n",
      "|    $    |  SYM  |  $  | quantmod |   $   |    0     |    0    |\n",
      "+---------+-------+-----+----------+-------+----------+---------+\n",
      "|    a    | PRON  | DT  | compound |   x   |    1     |    1    |\n",
      "+---------+-------+-----+----------+-------+----------+---------+\n",
      "| billion |  NUM  | CD  |   pobj   | xxxx  |    1     |    0    |\n",
      "+---------+-------+-----+----------+-------+----------+---------+\n"
     ]
    }
   ],
   "source": [
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0be560",
   "metadata": {},
   "source": [
    "### Visualizing Dependency Parsing\n",
    "\n",
    "* Dependency parsing is the process of extracting the dependency parse of a sentence to represent its grammatical structure. It defines the dependency relationship between headwords of their dependents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f165a890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "349ae2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"2e4b6492972f4fe0a2d6a6051323f4fa-0\" class=\"displacy\" width=\"1150\" height=\"287.0\" direction=\"ltr\" style=\"max-width: none; height: 287.0px; color: #000000; background: #AAFFFF; font-family: Source Sans Pro; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"150\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"150\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"250\">looking</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"250\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">at</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">buying</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"550\">U.K.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"550\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">startup</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">for</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">$</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"197.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1050\">billion</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1050\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-0\" stroke-width=\"2px\" d=\"M62,152.0 62,118.66666666666666 247.0,118.66666666666666 247.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,154.0 L58,146.0 66,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-1\" stroke-width=\"2px\" d=\"M162,152.0 162,135.33333333333334 244.0,135.33333333333334 244.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M162,154.0 L158,146.0 166,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-2\" stroke-width=\"2px\" d=\"M262,152.0 262,135.33333333333334 344.0,135.33333333333334 344.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M344.0,154.0 L348.0,146.0 340.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-3\" stroke-width=\"2px\" d=\"M362,152.0 362,135.33333333333334 444.0,135.33333333333334 444.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pcomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M444.0,154.0 L448.0,146.0 440.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-4\" stroke-width=\"2px\" d=\"M462,152.0 462,135.33333333333334 544.0,135.33333333333334 544.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M544.0,154.0 L548.0,146.0 540.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-5\" stroke-width=\"2px\" d=\"M262,152.0 262,118.66666666666666 647.0,118.66666666666666 647.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M647.0,154.0 L651.0,146.0 643.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-6\" stroke-width=\"2px\" d=\"M662,152.0 662,135.33333333333334 744.0,135.33333333333334 744.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M744.0,154.0 L748.0,146.0 740.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-7\" stroke-width=\"2px\" d=\"M862,152.0 862,118.66666666666666 1047.0,118.66666666666666 1047.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M862,154.0 L858,146.0 866,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-8\" stroke-width=\"2px\" d=\"M962,152.0 962,135.33333333333334 1044.0,135.33333333333334 1044.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M962,154.0 L958,146.0 966,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-9\" stroke-width=\"2px\" d=\"M762,152.0 762,102.0 1050.0,102.0 1050.0,152.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2e4b6492972f4fe0a2d6a6051323f4fa-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1050.0,154.0 L1054.0,146.0 1046.0,146.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options = {'compact':True, 'distance':100, 'bg':\"#AAFFFF\", \"font\":\"Source Sans Pro\"}\n",
    "displacy.render(doc, style='dep', jupyter=True, options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83338344",
   "metadata": {},
   "source": [
    "### Sentence Boundary Detection\n",
    "\n",
    "Sentence boundary detection is the process of locating the start and end of sentences in a given text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f7787f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "para = \"\"\"In this lecture, you will learn how to detect sentences in a large paragraph. Later on, you can apply other processing techniques to these sentences.\n",
    "ðŸ”Š Watch till last for a detailed description\n",
    "\n",
    "ðŸ’¯ Read Full Blog with Code\n",
    "       https://kgptalkie.com\n",
    "ðŸ’¬ Leave your comments and doubts in the comment section\n",
    "ðŸ“Œ Save this channel and video for watch later\n",
    "ðŸ‘ Like this video to show your support and love â¤ï¸\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbb4545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28f03634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[In,\n",
       " this,\n",
       " lecture,\n",
       " ,,\n",
       " you,\n",
       " will,\n",
       " learn,\n",
       " how,\n",
       " to,\n",
       " detect,\n",
       " sentences,\n",
       " in,\n",
       " a,\n",
       " large,\n",
       " paragraph,\n",
       " .,\n",
       " Later,\n",
       " on,\n",
       " ,,\n",
       " you,\n",
       " can,\n",
       " apply,\n",
       " other,\n",
       " processing,\n",
       " techniques,\n",
       " to,\n",
       " these,\n",
       " sentences,\n",
       " .,\n",
       " ,\n",
       " ðŸ”Š,\n",
       " Watch,\n",
       " till,\n",
       " last,\n",
       " for,\n",
       " a,\n",
       " detailed,\n",
       " description,\n",
       " \n",
       " ,\n",
       " ðŸ’¯,\n",
       " Read,\n",
       " Full,\n",
       " Blog,\n",
       " with,\n",
       " Code,\n",
       " \n",
       "        ,\n",
       " https://kgptalkie.com,\n",
       " ,\n",
       " ðŸ’¬,\n",
       " Leave,\n",
       " your,\n",
       " comments,\n",
       " and,\n",
       " doubts,\n",
       " in,\n",
       " the,\n",
       " comment,\n",
       " section,\n",
       " ,\n",
       " ðŸ“Œ,\n",
       " Save,\n",
       " this,\n",
       " channel,\n",
       " and,\n",
       " video,\n",
       " for,\n",
       " watch,\n",
       " later,\n",
       " ,\n",
       " ðŸ‘,\n",
       " Like,\n",
       " this,\n",
       " video,\n",
       " to,\n",
       " show,\n",
       " your,\n",
       " support,\n",
       " and,\n",
       " love,\n",
       " â¤,\n",
       " ï¸]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "931a8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = list(doc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a3184c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[In this lecture, you will learn how to detect sentences in a large paragraph.,\n",
       " Later on, you can apply other processing techniques to these sentences.,\n",
       " ðŸ”Š Watch till last for a detailed description\n",
       " \n",
       " ðŸ’¯ Read Full Blog with Code\n",
       "        https://kgptalkie.com\n",
       " ðŸ’¬ Leave your comments and doubts in the comment section\n",
       " ðŸ“Œ,\n",
       " Save this channel and video for watch later\n",
       " ðŸ‘,\n",
       " Like this video to show your support and love â¤ï¸]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac1ef71",
   "metadata": {},
   "source": [
    "### Stop Words\n",
    "\n",
    "Stop words are the most common words in a language. In the english language, some examples of stop words are the,are,but, and they.\n",
    "\n",
    "\n",
    "i am eating -> i eating\n",
    "\n",
    "\n",
    "i was eating -> i eating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2cc162aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15f5f160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'d\",\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'are',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'ca',\n",
       " 'call',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'could',\n",
       " 'did',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'done',\n",
       " 'down',\n",
       " 'due',\n",
       " 'during',\n",
       " 'each',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'eleven',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'empty',\n",
       " 'enough',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'except',\n",
       " 'few',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'first',\n",
       " 'five',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forty',\n",
       " 'four',\n",
       " 'from',\n",
       " 'front',\n",
       " 'full',\n",
       " 'further',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'had',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'indeed',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'last',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'made',\n",
       " 'make',\n",
       " 'many',\n",
       " 'may',\n",
       " 'me',\n",
       " 'meanwhile',\n",
       " 'might',\n",
       " 'mine',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'move',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " \"n't\",\n",
       " 'name',\n",
       " 'namely',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'nâ€˜t',\n",
       " 'nâ€™t',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'part',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'please',\n",
       " 'put',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 're',\n",
       " 'really',\n",
       " 'regarding',\n",
       " 'same',\n",
       " 'say',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'serious',\n",
       " 'several',\n",
       " 'she',\n",
       " 'should',\n",
       " 'show',\n",
       " 'side',\n",
       " 'since',\n",
       " 'six',\n",
       " 'sixty',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhere',\n",
       " 'still',\n",
       " 'such',\n",
       " 'take',\n",
       " 'ten',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'two',\n",
       " 'under',\n",
       " 'unless',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'used',\n",
       " 'using',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'was',\n",
       " 'we',\n",
       " 'well',\n",
       " 'were',\n",
       " 'what',\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'would',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'â€˜d',\n",
       " 'â€˜ll',\n",
       " 'â€˜m',\n",
       " 'â€˜re',\n",
       " 'â€˜s',\n",
       " 'â€˜ve',\n",
       " 'â€™d',\n",
       " 'â€™ll',\n",
       " 'â€™m',\n",
       " 'â€™re',\n",
       " 'â€™s',\n",
       " 'â€™ve'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c191a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this lecture, you will learn how to detect sentences in a large paragraph.\n",
      "In\n",
      "lecture\n",
      ",\n",
      "learn\n",
      "detect\n",
      "sentences\n",
      "large\n",
      "paragraph\n",
      ".\n",
      "Later on, you can apply other processing techniques to these sentences.\n",
      "\n",
      "Later\n",
      ",\n",
      "apply\n",
      "processing\n",
      "techniques\n",
      "sentences\n",
      ".\n",
      "\n",
      "\n",
      "ðŸ”Š Watch till last for a detailed description\n",
      "\n",
      "ðŸ’¯ Read Full Blog with Code\n",
      "       https://kgptalkie.com\n",
      "ðŸ’¬ Leave your comments and doubts in the comment section\n",
      "ðŸ“Œ\n",
      "ðŸ”Š\n",
      "Watch\n",
      "till\n",
      "detailed\n",
      "description\n",
      "\n",
      "\n",
      "\n",
      "ðŸ’¯\n",
      "Read\n",
      "Full\n",
      "Blog\n",
      "Code\n",
      "\n",
      "       \n",
      "https://kgptalkie.com\n",
      "\n",
      "\n",
      "ðŸ’¬\n",
      "Leave\n",
      "comments\n",
      "doubts\n",
      "comment\n",
      "section\n",
      "\n",
      "\n",
      "ðŸ“Œ\n",
      "Save this channel and video for watch later\n",
      "ðŸ‘\n",
      "Save\n",
      "channel\n",
      "video\n",
      "watch\n",
      "later\n",
      "\n",
      "\n",
      "ðŸ‘\n",
      "Like this video to show your support and love â¤ï¸\n",
      "Like\n",
      "video\n",
      "support\n",
      "love\n",
      "â¤\n",
      "ï¸\n"
     ]
    }
   ],
   "source": [
    "for sent in sents:\n",
    "    print(sent.text)\n",
    "    for token in sent:\n",
    "        if token.text not in stopwords:\n",
    "            print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0c73df",
   "metadata": {},
   "source": [
    "### Lemmatization\n",
    "\n",
    "\n",
    "Lemmatization is the process of reducing inflected forms of a word while still ensuring that the reduced form belongs to the language. This reduced form or root word is called a lemma.\n",
    "\n",
    "\n",
    "\n",
    "Playing\n",
    "\n",
    "Plays  -----> Play ----> Common root form 'play'\n",
    "\n",
    "Played\n",
    "\n",
    "\n",
    "\n",
    "Lemmatization is necessary because it helps you reduce the inflected forms of a word so that they can be analyzed as a single item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7e930285",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'playing played plays play'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c72515ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6a7057b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playing play\n",
      "played play\n",
      "plays play\n",
      "play play\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91169e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
